{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "Retrain pretrained models from pytorch to fit CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cpu\":\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010) )  # Normalize the images\n",
    "])\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train image classifer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# initial learning rate\n",
    "INITIAL_LR = 0.001\n",
    "\n",
    "# momentum for optimizer\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "# L2 regularization strength\n",
    "REG = 1e-3\n",
    "\n",
    "# total number of training epochs\n",
    "EPOCHS = 5\n",
    "\n",
    "# number of epochs before decay learning rate \n",
    "DECAY_EPOCHS = 5\n",
    "\n",
    "# rate of decay for learning rate\n",
    "DECAY = 0.1\n",
    "\n",
    "# the folder where the trained model is saved\n",
    "CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "\n",
    "num_classes = 10  # Number of classes in CIFAR-10\n",
    "\n",
    "# ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)  # Initialize ResNet-50 model\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)  # Modify output layer to match number of classes\n",
    "model = model.to(device)\n",
    "\n",
    "# DenseNet model\n",
    "# model = models.densenet121(pretrained=True)\n",
    "# model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "# model = model.to(device)\n",
    "\n",
    "# VGG16 model\n",
    "# model = models.vgg16(pretrained = True)\n",
    "# model.classifier[6] = nn.Linear(model.classifier[6].in_features,num_classes)\n",
    "# model = model.to(device)\n",
    "\n",
    "# VGG19 model\n",
    "# model = models.vgg19(pretrained=True)\n",
    "# model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "# model = model.to(device)\n",
    "\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Add optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training: 100%|██████████| 782/782 [06:04<00:00,  2.15batch/s, train_loss=0.433]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Train CNN models\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "# start the training/validation process\n",
    "best_acc = 0\n",
    "current_learning_rate = INITIAL_LR\n",
    "\n",
    "print(\"==> Training starts!\")\n",
    "print(\"=\"*50)\n",
    "for i in range(0, EPOCHS):\n",
    "    # handle the learning rate scheduler.\n",
    "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
    "        current_learning_rate = current_learning_rate * DECAY\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = current_learning_rate\n",
    "        print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "    \n",
    "    #######################\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    print(\"Epoch %d:\" %i)\n",
    "    # this help you compute the training accuracy\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    train_loss = 0 # track training loss if you want\n",
    "    \n",
    "    # Train the model for 1 epoch.\n",
    "    with tqdm(train_loader, unit=\"batch\") as t:\n",
    "        for batch_idx, (inputs, targets) in enumerate(t):\n",
    "            ####################################\n",
    "            # copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # compute the output and loss\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.long())\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # apply gradient and update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_examples += (predicted == targets).sum().item()\n",
    "            total_examples += inputs.shape[0]\n",
    "            ####################################\n",
    "            t.set_description(f\"Epoch {i}: Training\")\n",
    "            t.set_postfix(train_loss=train_loss / len(train_loader))\n",
    "                \n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "    \n",
    "    # save the model checkpoint\n",
    "    if avg_acc > best_acc: \n",
    "        best_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "            os.makedirs(CHECKPOINT_FOLDER)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'state_dict': model.state_dict(),\n",
    "                 'epoch': i,\n",
    "                 'lr': current_learning_rate}\n",
    "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'resnet50.pth'))\n",
    "        \n",
    "print(\"=\"*50)\n",
    "print(f\"==> Optimization finished! Best training accuracy: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiong\\miniforge3\\envs\\ECE661\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.931, 0.21431485845879383)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model accuracy\n",
    "from torchvision import models\n",
    "import os\n",
    "from util import test_model\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64, shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = 10  # Number of classes in CIFAR-10\n",
    "\n",
    "# ResNet-50 model\n",
    "# model = models.resnet50(pretrained=True)  # Initialize ResNet-50 model\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)  # Modify output layer to match number of classes\n",
    "# model = model.to(device)\n",
    "# model.load_state_dict(torch.load(os.path.join(CHECKPOINT_FOLDER, 'resnet50_.pth'))['state_dict']) \n",
    "\n",
    "# DenseNet model\n",
    "# model = models.densenet121(pretrained=True)\n",
    "# model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "# model = model.to(device)\n",
    "# model.load_state_dict(torch.load(os.path.join(CHECKPOINT_FOLDER, 'densenet_.pth'))['state_dict']) \n",
    "\n",
    "# VGG16\n",
    "model = models.vgg16(pretrained = True)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features,num_classes)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_FOLDER, 'vgg16_.pth'))['state_dict']) \n",
    "\n",
    "# VGG19 model\n",
    "# model = models.vgg19(pretrained=True)\n",
    "# model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "# model = model.to(device)\n",
    "# model.load_state_dict(torch.load(os.path.join(CHECKPOINT_FOLDER, 'vgg19_.pth'))['state_dict']) \n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE661",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
